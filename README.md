# Local-LLM
![image](https://github.com/user-attachments/assets/a6cbe9a4-994f-4e42-a872-4aababfecd85)

This is a Streamlit application that allows users to interact with various local language models (LLMs) using the Langchain library. The app provides a user-friendly interface to manage model selection, chat history, and user input.

## Requirements

To run this application, you need to have the following installed:

- Python 3.7 or higher
- Streamlit
- Langchain
- OllamaLLM

You can install the required libraries using pip:

```bash
pip install streamlit langchain langchain-ollama
```

## Getting Started

- **1. Clone the repository**
```bash
git clone https://github.com/Nameless0-0/Local-LLM
cd <repository-directory>
```

- **2. Run the Application: Execute the following command in your terminal:**
```bash
streamlit run main.py
```
- **3. Open your web browser.**
After running the command, a new tab should open in your default web browser displaying the chat application.

## Usage Instructions

1. **Model Selection:**
   - Use the dropdown in the sidebar to choose an LLM model from the predefined list or enter a custom model name.

2. **Chat Input:**
   - Type your message in the input box and hit Enter to send it to the selected model. 

3. **Chat History:**
   - The conversation history is displayed in the main area, showing both user and AI messages.

## Reference:
https://www.youtube.com/watch?v=zKGeRWjJlTU&list=LL&index=5
https://www.youtube.com/watch?v=d0o89z134CQ
